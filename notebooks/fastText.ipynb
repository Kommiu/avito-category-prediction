{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В это тетрадке я пытаюсь выжать приличный скор из фейсбуковского fastText'a.  Для этого я опредляю несколько оберток, чтобы получить более привичный интерфейс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from pymystem3 import Mystem\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastext не умеет предсказывать несколько примеров сразу\n",
    "# поэтому вызваем его в цикле, заодно обрезая лишнее\n",
    "def predict_ft(model, texts):\n",
    "    labels = np.array([model.predict(text.strip('\\n'))[0][0].strip('__label__') for text in texts])\n",
    "    return labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# простая функция для кроссвалидация, использующая заранее созраненные в файлы фолды в подходящем формате\n",
    "def cross_val_score(data_path,\n",
    "                    scorer, model_params):\n",
    "    \n",
    "    data_dir = Path(data_path)\n",
    "    n_files = len(list(data_dir.glob('*.txt*')))\n",
    "    # на каждый фолд должно приходится три файла: train, test-text, test-label\n",
    "    assert n_files % 3 == 0\n",
    "    n_splits = n_files // 3\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        train_path = Path(data_path, f'train_{fold}.txt')\n",
    "        test_path = Path(data_path, f'test_{fold}.txt')\n",
    "        label_path = Path(test_path.parent, test_path.name + '.label')\n",
    "        with open(test_path) as f:\n",
    "            test_texts = f.readlines()\n",
    "            \n",
    "        test_labels = pd.read_csv(label_path, header=None,names=['label'])\n",
    "        \n",
    "        model = fastText.train_supervised(train_path.as_posix(), **model_params)\n",
    "        \n",
    "        preds = predict_ft(model, test_texts)\n",
    "        scores.append(scorer(test_labels, preds))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# велосипед для перебора параметров\n",
    "\n",
    "def random_search(data_path,\n",
    "                  param_grid, scorer,  n_trials=10):\n",
    "    best_score  = 0 \n",
    "    best_paramss = {}\n",
    "    scores = {}\n",
    "    while n_trials:\n",
    "        model_params = {\n",
    "            k: np.random.choice(param_grid[k])\n",
    "            for k in param_grid\n",
    "        }\n",
    "        \n",
    "        # зарардкоженная проверка на наличие готовых ембеддингов\n",
    "        if model_params['pretrainedVectors'] != '':\n",
    "            model_params['dim'] = 300\n",
    "            \n",
    "        # гарантируем чтобы maxn был не меньше minn\n",
    "        model_params['maxn'] = max(model_params['maxn'], model_params['minn'])\n",
    "        \n",
    "        # проверяем что мы еще не пробовали этот набор параметров\n",
    "        if tuple(model_params.items()) not in scores:\n",
    "            \n",
    "            score = cross_val_score(data_path,\n",
    "                                   scorer, model_params)\n",
    "            scores[tuple(model_params.items())] = score\n",
    "            n_trials -= 1\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = model_params\n",
    "\n",
    "    return best_score, best_params, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minCount': range(1,6) ,\n",
    "    'wordNgrams': range(1,4),\n",
    "    'minn': range(3) ,\n",
    "    'maxn': range(5),\n",
    "    'epoch': [15,20],\n",
    "    'thread': [3],\n",
    "    'dim': [100, 150, 200, 250],\n",
    "    'lr': np.linspace(0.1, 0.2, 50),\n",
    "    'lrUpdateRate': np.arange(1,10)*100,\n",
    "    'pretrainedVectors': ['', '../embeddings/ft_native_300_ru_wiki_lenta_lemmatize.vec']\n",
    "}\n",
    "best_score_2, best_params_2, scores_2 = random_search('../data/ft/lemmatized/kfolds',\n",
    "                                                      param_grid, accuracy_score, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minCount': range(1,6) ,\n",
    "    'wordNgrams': range(1,4),\n",
    "    'minn': range(3) ,\n",
    "    'maxn': range(5),\n",
    "    'epoch': [15,20],\n",
    "    'thread': [3],\n",
    "    'dim': [100, 150, 200, 250],\n",
    "    'lr': np.linspace(0.1, 0.2, 50),\n",
    "    'lrUpdateRate': np.arange(1,10)*100,\n",
    "    'pretrainedVectors': ['']\n",
    "}\n",
    "best_score_3, best_params_3, scores_3 = random_search('../data/ft/lemmatized/kfolds',\n",
    "                                                      param_grid, accuracy_score, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minCount': 3,\n",
       " 'wordNgrams': 3,\n",
       " 'minn': 0,\n",
       " 'maxn': 4,\n",
       " 'epoch': 20,\n",
       " 'thread': 3,\n",
       " 'dim': 100,\n",
       " 'lr': 0.1979591836734694,\n",
       " 'lrUpdateRate': 300,\n",
       " 'pretrainedVectors': ''}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871888863726744"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728234039414533"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minCount': range(1,6) ,\n",
    "    'wordNgrams': range(1,4),\n",
    "    'minn': [2] ,\n",
    "    'maxn': [5],\n",
    "    'epoch': [5, 10, 15],\n",
    "    'thread': [6],\n",
    "    'dim': [50, 100, 200],\n",
    "    'lr': np.linspace(0.05, 0.2, 200),\n",
    "    'lrUpdateRate': np.arange(1,10)*100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_params, scores = random_search('../data/ft/lemmatized/kfolds', '../data/json/kfolds/', 'lemmatized',\n",
    "              param_grid, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728872657040551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minCount': 1,\n",
       " 'wordNgrams': 2,\n",
       " 'minn': 2,\n",
       " 'maxn': 5,\n",
       " 'epoch': 15,\n",
       " 'thread': 6,\n",
       " 'dim': 200,\n",
       " 'lr': 0.17512562814070354,\n",
       " 'lrUpdateRate': 400}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не очень впечатляющие результаты, возможн стоило сначала обучить свои ембеддинги на трейне, и далее использовать их, а также перебирать параметры подольше. Но другие модели выдают лучший результат при меньших затратах времени, так что я решил оставить fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
