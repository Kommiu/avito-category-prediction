{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from pymystem3 import Mystem\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ft(model, texts):\n",
    "    labels = np.array([model.predict(text)[0][0].strip('__label__') for text in texts])\n",
    "    return labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(data_path, data_type,\n",
    "                    scorer, model_params):\n",
    "    \n",
    "    data_dir = Path(data_path)\n",
    "    n_files = len(list(data_dir.glob('*.txt')))\n",
    "    assert n_files % 3 == 0\n",
    "    n_splits = n_files // 3\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for fold in range(n_splits):\n",
    "        train_path = Path(data_path, f'train_{fold}.txt')\n",
    "        test_path = Path(data_path, f'test_{fold}.txt')\n",
    "        label_pth = Path(test_path, '.label')\n",
    "        \n",
    "        test = pd.read_json(test_path, orient='records', lines=True)\n",
    "        with open(test_path) as f:\n",
    "            test_texts = f.readlines()\n",
    "            \n",
    "        test_labels = pd.read_csv(label_path, header=None,names=['label'])\n",
    "        \n",
    "        model = fastText.train_supervised(train_path.as_posix(), **model_params)\n",
    "        \n",
    "        preds = predict_ft(model, test_texts)\n",
    "        scores.append(scorer(test_labels, preds))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(train_dir, test_dir, data_type,\n",
    "                  param_grid, scorer,  n_trials=10):\n",
    "    best_score  = 0 \n",
    "    best_paramss = {}\n",
    "    scores = {}\n",
    "    for i in range(n_trials):\n",
    "        model_params = {\n",
    "            k: np.random.choice(param_grid[k])\n",
    "            for k in param_grid\n",
    "        }\n",
    "        \n",
    "        model_params['maxn'] = max(model_params['maxn'], model_params['minn'])\n",
    "        if tuple(model_params.items()) not in scores:\n",
    "            score = cross_val_score(train_dir, test_dir, data_type,\n",
    "                                   scorer, model_params)\n",
    "            scores[tuple(model_params.items())] = score\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = model_params\n",
    "\n",
    "    return best_score, best_params, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minCount': range(1,6) ,\n",
    "    'wordNgrams': range(1,4),\n",
    "    'minn': [2] ,\n",
    "    'maxn': [5],\n",
    "    'epoch': [5, 10, 15],\n",
    "    'thread': [6],\n",
    "    'dim': [50, 100, 200],\n",
    "    'lr': np.linspace(0.05, 0.2, 200),\n",
    "    'lrUpdateRate': np.arange(1,10)*100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_params, scores = random_search('../data/ft/lemmatized/kfolds', '../data/json/kfolds/', 'lemmatized',\n",
    "              param_grid, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728872657040551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minCount': 1,\n",
       " 'wordNgrams': 2,\n",
       " 'minn': 2,\n",
       " 'maxn': 5,\n",
       " 'epoch': 15,\n",
       " 'thread': 6,\n",
       " 'dim': 200,\n",
       " 'lr': 0.17512562814070354,\n",
       " 'lrUpdateRate': 400}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'minCount': range(1,6) ,\n",
    "    'wordNgrams': range(1,4),\n",
    "    'minn': range(3) ,\n",
    "    'maxn': range(5),\n",
    "    'epoch': [15,20],\n",
    "    'thread': [6],\n",
    "    'dim': [100, 150, 200, 250],\n",
    "    'lr': np.linspace(0.1, 0.2, 50),\n",
    "    'lrUpdateRate': np.arange(1,10)*100,\n",
    "}\n",
    "best_score_2, best_params_2, scores_2 = random_search('../data/ft/lemmatized/kfolds', '../data/json/kfolds/',\n",
    "                                                      'lemmatized', param_grid, accuracy_score, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
