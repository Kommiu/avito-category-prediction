{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from importlib import reload\n",
    "import models\n",
    "import training_utils as tu\n",
    "\n",
    "from params import SEED\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_embeddings = vocab.Vectors(name = '../embeddings/ft_native_300_ru_wiki_lenta_lemmatize.vec',\n",
    "                                  cache = '../embeddings',\n",
    "                                  unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = data.Field(use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padder(min_len=4):\n",
    "    def pad(seq):\n",
    "        if len(seq) >= min_len:\n",
    "            return seq\n",
    "        else:\n",
    "            return seq + ['<unk>'] * (min_len - len(seq))\n",
    "    return pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(preprocessing=make_padder(4))\n",
    "LABEL = data.LabelField()\n",
    "fields = {'category_id': ('label', LABEL), 'lemmatized': ('text', TEXT), 'jacs': ('num', NUM),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = data.TabularDataset.splits(\n",
    "                                        path = '../data/json',\n",
    "                                        train = 'train.json',\n",
    "                                        validation = 'valid.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.vocab as vocab\n",
    "\n",
    "custom_embeddings = vocab.Vectors(name = '../embeddings/ft_native_300_ru_wiki_lenta_lemmatize.vec',\n",
    "                                  cache = '../embeddings',\n",
    "                                  unk_init = torch.Tensor.normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 296604\n",
      "Number of classes: 54\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "TEXT.build_vocab(train_data, vectors=custom_embeddings)\n",
    "LABEL.build_vocab(train_data)\n",
    "print(f'Vocab size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda ex: len(ex.text),\n",
    "    sort_within_batch = False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(models)\n",
    "from models import CNN_jaccard as CNN\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = custom_embeddings.dim\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "LINEAR_SIZES = [54, 200] \n",
    "model = CNN(INPUT_DIM, OUTPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, LINEAR_SIZES,  DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(embeddings)\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = '../runs/cnn_jacs'\n",
    "if Path(log_dir).exists():\n",
    "    Path(log_dir).rmdir()\n",
    "    \n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch: 1 | Epoch Time: 5m 36:s \n",
      "\tEpoch: 2 | Epoch Time: 5m 38:s \n"
     ]
    }
   ],
   "source": [
    "tu.train_model(model, train_iterator, valid_iterator, optimizer,criterion,'cnn_jacs', 10, '_',writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'á¶¦'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
